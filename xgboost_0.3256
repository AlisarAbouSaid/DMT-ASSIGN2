import pandas as pd
import numpy as np
import xgboost as xgb
import matplotlib
import gc
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt

matplotlib.use('TkAgg')  # Needed for GUI environments


# -------------------- Feature Engineering --------------------

def add_custom_features(df):
    # Add price difference to visitor history feature
    if 'price_usd' in df.columns and 'visitor_hist_adr_usd' in df.columns:
        df['price_diff_to_user_hist'] = df['price_usd'] - df['visitor_hist_adr_usd']
    return df


def add_price_per_star(df):
    if 'price_usd' in df.columns and 'prop_starrating' in df.columns:
        df['price_per_star'] = df['price_usd'] / df['prop_starrating'].replace(0, np.nan)
        df['price_per_star'] = df['price_per_star'].fillna(df['price_per_star'].mean())
    return df


# -------------------- Preprocessing Functions --------------------

def load_data(filename):
    return pd.read_csv(filename)


def add_date_features(df):
    if 'date_time' in df.columns:
        df['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')
        df['year'] = df['date_time'].dt.year
        df['month'] = df['date_time'].dt.month
        df['day'] = df['date_time'].dt.day
        df['hour'] = df['date_time'].dt.hour
    return df


def normalize_features(df):
    if 'srch_query_affinity_score' in df.columns:
        df['srch_query_affinity_score'] = df['srch_query_affinity_score'].fillna(df['srch_query_affinity_score'].mean())
        df['srch_query_affinity_score'] = (df['srch_query_affinity_score'] - df['srch_query_affinity_score'].mean()) / \
                                          df['srch_query_affinity_score'].std()
    if 'position' in df.columns:
        df['position'] = (df['position'] - df['position'].mean()) / df['position'].std()
    return df


def fill_missing(df):
    for col in df.select_dtypes(include=[np.number]).columns:
        df[col] = df[col].fillna(df[col].mean())
    return df


def add_requested_interaction_features(df):
    if 'visitor_hist_starrating' in df.columns and 'prop_starrating' in df.columns:
        df['star_diff'] = df['prop_starrating'] - df['visitor_hist_starrating']
        df['star_ratio'] = df['prop_starrating'] / df['visitor_hist_starrating'].replace(0, np.nan)

    if 'visitor_hist_adr_usd' in df.columns and 'price_usd' in df.columns:
        df['price_diff_to_hist'] = df['price_usd'] - df['visitor_hist_adr_usd']
        df['price_ratio_to_hist'] = df['price_usd'] / df['visitor_hist_adr_usd'].replace(0, np.nan)

    if 'prop_location_score1' in df.columns and 'prop_review_score' in df.columns:
        df['location_review_product'] = df['prop_location_score1'] * df['prop_review_score']
        df['location_minus_review'] = df['prop_location_score1'] - df['prop_review_score']

    if 'srch_length_of_stay' in df.columns and 'prop_review_score' in df.columns:
        df['stay_review_score'] = df['srch_length_of_stay'] * df['prop_review_score']

    return df


def preprocess_training_data(df, kind="train", encoders=None):
    drop_competitor_cols = [
        'comp1_rate', 'comp1_inv', 'comp1_rate_percent_diff',
        'comp2_rate', 'comp2_inv', 'comp2_rate_percent_diff',
        'comp3_rate', 'comp3_inv', 'comp3_rate_percent_diff',
        'comp4_rate', 'comp4_inv', 'comp4_rate_percent_diff',
        'comp5_rate', 'comp5_inv', 'comp5_rate_percent_diff',
        'comp6_rate', 'comp6_inv', 'comp6_rate_percent_diff',
        'comp7_rate', 'comp7_inv', 'comp7_rate_percent_diff',
        'comp8_rate', 'comp8_inv', 'comp8_rate_percent_diff'
    ]
    df = df.drop(columns=[col for col in drop_competitor_cols if col in df.columns], errors='ignore')
    df = fill_missing(df)
    df = add_date_features(df)
    df = add_custom_features(df)
    df = add_price_per_star(df)
    df = normalize_features(df)



    labels = None
    if kind == "train":
        if 'click_bool' in df.columns:
            labels = df['click_bool'].copy()
            df = df.drop(columns=['click_bool'])

    return df, labels, encoders


# -------------------- Main Pipeline --------------------

if __name__ == "__main__":
    print("ðŸš€ Starting XGBoost Training Pipeline...")

    # Paths
    train_file = "training_set_VU_DM.csv"
    test_file = "test_set_VU_DM.csv"

    # Load data
    train_df = load_data(train_file)
    test_df = load_data(test_file)

    # Preprocess
    X_train, y_train, encoders = preprocess_training_data(train_df, kind="train")
    X_test, _, _ = preprocess_training_data(test_df, kind="test", encoders=encoders)

    # Keep identifiers for submission
    srch_ids_test = X_test['srch_id'].copy()
    prop_ids_test = X_test['prop_id'].copy()

    # Drop non-feature columns
    drop_cols = [col for col in ['srch_id', 'prop_id', 'date_time','price_usd' ,'prop_starrating','visitor_hist_adr_usd','prop_location_score1','prop_review_score','srch_length_of_stay'] if col in X_train.columns]
    X_train_model = X_train.drop(columns=drop_cols)
    X_test_model = X_test.drop(columns=drop_cols)

    # Align test set with training columns
    missing_cols = set(X_train_model.columns) - set(X_test_model.columns)
    for col in missing_cols:
        X_test_model[col] = 0

    X_test_model = X_test_model[X_train_model.columns]

    # Train/Validation Split
    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
        X_train_model, y_train, test_size=0.2, random_state=42
    )

    # Train XGBoost
    model = xgb.XGBClassifier(
        objective='binary:logistic',
        use_label_encoder=False,
        eval_metric='logloss',
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1
    )

    print("ðŸ§  Training model...")
    model.fit(X_train_split, y_train_split)

    # Validation Evaluation
    val_preds = model.predict(X_val_split)
    val_accuracy = accuracy_score(y_val_split, val_preds)
    print(f"âœ… Validation Accuracy: {val_accuracy:.4f}")

    # Confusion Matrix
    cm = confusion_matrix(y_val_split, val_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])
    disp.plot()
    plt.title("Validation Confusion Matrix")
    plt.show()

    # Test Predictions
    print("ðŸ“ˆ Predicting on test data...")
    click_probs = model.predict_proba(X_test_model)[:, 1]

    result_df = pd.DataFrame({
        'srch_id': srch_ids_test,
        'prop_id': prop_ids_test,
        'click_proba': click_probs
    })

    result_df['rank'] = result_df.groupby('srch_id')['click_proba'].rank(method='first', ascending=False)

    submission = result_df.sort_values(by=['srch_id', 'rank'])[['srch_id', 'prop_id']]
    submission.to_csv("submission.csv", index=False)
    print("âœ… Submission file saved as 'submission.csv'")

    # Feature Importance
    xgb.plot_importance(model)
    plt.title("XGBoost Feature Importance")
    plt.show()

    # Free memory
    del model, X_train, X_test, X_train_model, X_test_model
    gc.collect()
